[Linux下的IO监控与分析](https://blog.csdn.net/tjcwt2011/article/details/81143868)

近期要在公司内部做个Linux IO方面的培训, 整理下手头的资料给大家分享下,各种IO监视工具在Linux IO 体系结构中的位置

![](image/14234440-f3c0f93e0b5a4881a8345ddf617eb7ef.jpg)



    源自 Linux Performance and Tuning Guidelines.pdf

## 1 系统级IO监控

iostat

　　iostat -xdm 1    # 个人习惯
 ![](image/14213642-6fe59e93a2154ddcafc6fe14d1db25bd.jpg)

*  %util         代表磁盘繁忙程度。100% 表示磁盘繁忙, 0%表示磁盘空闲。但是注意,磁盘繁忙不代表磁盘(带宽)利用率高

* argrq-sz    提交给驱动层的IO请求大小,一般不小于4K,不大于max(readahead_kb, max_sectors_kb)

              可用于判断当前的IO模式,一般情况下,尤其是磁盘繁忙时, 越大代表顺序,越小代表随机


* svctm        一次IO请求的服务时间,对于单块盘,完全随机读时,基本在7ms左右,既寻道+旋转延迟时间



注: 各统计量之间关系

=======================================

%util = ( r/s  +  w/s) * svctm / 1000                        # 队列长度 =  到达率     *  平均服务时间
avgrq-sz = ( rMB/s + wMB/s) * 2048 / (r/s  + w/s)    # 2048 为 1M / 512

=======================================


## 总结:

iostat 统计的是通用块层经过合并(rrqm/s, wrqm/s)后,直接向设备提交的IO数据,可以反映系统整体的IO状况,但是有以下2个缺点:

* 1  距离业务层比较遥远,跟代码中的write,read不对应(由于系统预读 + pagecache + IO调度算法等因素, 也很难对应)

* 2  是系统级,没办法精确到进程,比如只能告诉你现在磁盘很忙,但是没办法告诉你是谁在忙,在忙什么？


## vmstat

命令是最常见的Linux/Unix监控工具，可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。这个命令是我查看Linux/Unix最喜爱的命令，一个是Linux/Unix都支持，二是相比top，我可以看到整个机器的CPU,内存,IO的使用情况，而不是单单看到各个进程的CPU使用率和内存使用率(使用场景不一样)

一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:

```

root@ubuntu:~# vmstat 2 1
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 1  0      0 3498472 315836 3819540    0    0     0     1    2    0  0  0 100  0
 ```


 现在开始实战讲解每个参数的意思。

* r 表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。

* b 表示阻塞的进程,这个不多说，进程阻塞，大家懂的。

* swpd 虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。

* free   空闲的物理内存的大小，我的机器内存总共8G，剩余3415M。

* buff   Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用300多M

* cache cache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)

* si  每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。

* so  每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。

* bi  块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte，我本机上没什么IO操作，所以一直是0，但是我曾在处理拷贝大量数据(2-3T)的机器上看过可以达到140000/s，磁盘写入速度差不多140M每秒

* bo 块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。

* in 每秒CPU的中断次数，包括时间中断

* cs 每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。

* us 用户CPU时间，我曾经在一个做加密解密很频繁的服务器上，可以看到us接近100,r运行队列达到80(机器在做压力测试，性能表现不佳)。

* sy 系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。

* id  空闲 CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。

* wt 等待IO CPU时间。


# 2 进程级IO监控

## iotop 和 pidstat (仅rhel6u系列)

iotop    顾名思义, io版的top

pidstat 顾名思义, 统计进程(pid)的stat,进程的stat自然包括进程的IO状况

这两个命令,都可以按进程统计IO状况,因此可以回答你以下二个问题
```
        当前系统哪些进程在占用IO,百分比是多少?
        占用IO的进程是在读?还是在写?读写量是多少?
```

* pidstat 参数很多,仅给出几个个人习惯
```
      pidstat -d  1                  #只显示IO
```

  ![](image/14220537-daf2222070dc4e6996e212e37fcdfbbe.jpg)

  pidstat -u -r -d -t 1        # -d IO 信息,

                                           # -r 缺页及内存信息
                                           # -u CPU使用率
                                           # -t 以线程为统计单位
                                           # 1  1秒统计一次

* iotop, 很简单,直接敲命令
![](image/14220629-d7086bd160b34115b8b5a536eb230785.jpg)

## block_dump, iodump

iotop   和 pidstat 用着很爽,但两者都依赖于/proc/pid/io文件导出的统计信息, 这个对于老一些的内核是没有的,比如rhel5u2

因此只好用以上2个穷人版命令来替代:

echo 1 > /proc/sys/vm/block_dump     # 开启block_dump,此时会把io信息输入到dmesg中

                                                        # 源码: submit_bio@ll_rw_blk.c:3213

watch -n 1 "dmesg -c | grep -oP \"\w+\d+\d+: (WRITE|READ)\" | sort | uniq -c"

                                                         # 不停的dmesg -c

echo 0 > /proc/sys/vm/block_dump      # 不用时关闭



也可以使用现成的脚本 iodump, 具体参见 http://code.google.com/p/maatkit/source/browse/trunk/util/iodump?r=5389



  iotop.stp

systemtap脚本,一看就知道是iotop命令的穷人复制版,需要安装Systemtap, 默认每隔5秒输出一次信息

stap iotop.stp                                     #  examples/io/iotop.stp

## 总结

进程级IO监控 ，

     可以回答系统级IO监控不能回答的2个问题
     距离业务层相对较近(例如,可以统计进程的读写量)

但是也没有办法跟业务层的read,write联系在一起,同时颗粒度较粗,没有办法告诉你,当前进程读写了哪些文件? 耗时? 大小 ？


# 3 业务级IO监控

##  ioprofile

  ioprofile 命令本质上是 lsof + strace, 具体下载可见 http://code.google.com/p/maatkit/

  ioprofile 可以回答你以下三个问题:

  * 1  当前进程某时间内,在业务层面读写了哪些文件(read, write)？

  * 2  读写次数是多少?(read, write的调用次数)

  * 3  读写数据量多少?(read, write的byte数)

  假设某个行为会触发程序一次IO动作,例如: "一个页面点击,导致后台读取A,B,C文件"

============================================

./io_event   # 假设模拟一次IO行为,读取A文件一次, B文件500次, C文件500次

  ioprofile  -p  `pidof  io_event` -c count   # 读写次数

  ![](image/14223128-27053f1d15ae47cba1c116d7bdb0d567.jpg)

  ioprofile  -p  `pidof  io_event` -c times   # 读写耗时

  ![](image/14223407-d127064d60df4e40953636d22d7555a2.jpg)

  ioprofile  -p  `pidof  io_event` -c sizes    # 读写大小

 ![](image/14223513-385b744622534f45ac04aff7ee16b3e1.jpg)


 注: ioprofile 仅支持多线程程序,对单线程程序不支持. 对于单线程程序的IO业务级分析,strace足以。

  ## 总结:

ioprofile本质上是strace,因此可以看到read,write的调用轨迹,可以做业务层的io分析(mmap方式无能为力)


# 4 文件级IO监控

   文件级IO监控可以配合/补充"业务级和进程级"IO分析

   文件级IO分析,主要针对单个文件, 回答当前哪些进程正在对某个文件进行读写操作.

   * 1 lsof   或者  ls /proc/pid/fd

   * 2  inodewatch.stp

lsof  告诉你 当前文件由哪些进程打开

lsof ../io   #  io目录 当前由 bash 和 lsof 两个进程打开

![](image/14224451-c0c8d14d03a34af6bf310a1390010886.jpg)


lsof 命令 只能回答静态的信息, 并且"打开" 并不一定"读取", 对于 cat ,echo这样的命令, 打开和读取都是瞬间的,lsof很难捕捉

可以用 inodewatch.stp 来弥补

stap inodewatch.stp major minor inode      # 主设备号, 辅设备号, 文件inode节点号

stap  inodewatch.stp  0xfd 0x00 523170    # 主设备号, 辅设备号, inode号,可以通过 stat 命令获得

![](image/14234837-9c3d150d50874b74ae1171ccfcbafd12.jpg)

# 5 IO模拟器

   iotest.py     # 见附录

 开发人员可以 利用 ioprofile (或者 strace) 做详细分析系统的IO路径,然后在程序层面做相应的优化。

 但是一般情况下调整程序,代价比较大,尤其是当不确定修改方案到底能不能有效时,最好有某种模拟途径以快速验证。

 以为我们的业务为例，发现某次查询时,系统的IO访问模式如下:

 * 访问了A文件一次

 * 访问了B文件500次, 每次16字节,   平均间隔 502K

 * 访问了C文件500次, 每次200字节, 平均间隔 4M

 这里 B,C文件是交错访问的, 既

 * 1 先访问B,读16字节,

 * 2 再访问C,读200字节,

 * 3 回到B,跳502K后再读16字节,

 * 4 回到C,跳4M后,再读200字节

 * 5 重复500次

strace 文件如下:

![](image/14233214-f2e87059cd844f70a2aa3c36f730d7fb.jpg)

一个简单朴素的想法, 将B,C交错读,改成先批量读B , 再批量读C,因此调整strace 文件如下:

![](image/14233318-bcda1c96a1f04e548b17ed7b8a8872c2.jpg)

将调整后的strace文件, 作为输入交给 iotest.py, iotest.py 按照 strace 文件中的访问模式, 模拟相应的IO

iotest.py -s io.strace -f fmap

fmap 为映射文件,将strace中的222,333等fd,映射到实际的文件中

```
111 = /opt/work/io/A.data
222 = /opt/work/io/B.data
333 = /opt/work/io/C.data
```

# 6 磁盘碎片整理

 一句话: 只要磁盘容量不常年保持80%以上,基本上不用担心碎片问题。

如果实在担心,可以用 defrag 脚本

# 7 其他IO相关命令

## blockdev 系列

=======================================

blockdev --getbsz /dev/sdc1             # 查看sdc1盘的块大小

block blockdev --getra /dev/sdc1      # 查看sdc1盘的预读(readahead_kb)大小

blockdev --setra 256 /dev/sdc1         # 设置sdc1盘的预读(readahead_kb)大小,低版的内核通过/sys设置,有时会失败,不如blockdev靠谱

=======================================
